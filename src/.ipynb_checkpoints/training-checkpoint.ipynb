{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six key points for effective transfer learning\n",
    "\n",
    "I would like to introduce the key points to build your own model based on MobileNet. The model is lightweight and fast but it has enough performance.\n",
    "\n",
    "## Import libraries\n",
    "\n",
    "Import the liblraries as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import coremltools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.applications import mobilenet\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    "\n",
    "I assign 25% of training dataset as validation dataset this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = '../dataset/movies'\n",
    "train_data_dir = '../dataset/training'\n",
    "result_dir = '../result'\n",
    "frame_interval = 3\n",
    "batch_size = 64\n",
    "epoch_count = 100\n",
    "validation_data_split_rate = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Labels\n",
    "\n",
    "I load the class labels from the \"classes.txt\" file, and then setup a list with removing the line separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the class labels\n",
    "with open('classes.txt', 'r') as fp:\n",
    "    lines = fp.readlines()        \n",
    "class_labels = []\n",
    "for line in lines:\n",
    "# The line separator will be; Win='\\r\\n', Mac='\\r', Linux='\\n'\n",
    "    line = line.rstrip('\\n')\n",
    "    class_labels.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 1:  Create training image and annotation automatically\n",
    "\n",
    "I am going to pick out a frame every interval specified in \"frame_interval\". The destination directory name is same as the name of movie file and it is the class label. For instance, if you have \"deep_learning.mov\", \"deep_learning\" directory will be made under the \"../dataset/training\" directory and the name of the image file will be set from 0.jpg to nnn.jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of images & path: 59 images under../dataset/training/five\n",
      "# of images & path: 56 images under../dataset/training/one\n",
      "# of images & path: 61 images under../dataset/training/three\n",
      "# of images & path: 56 images under../dataset/training/two\n",
      "# of images & path: 59 images under../dataset/training/four\n"
     ]
    }
   ],
   "source": [
    "# Loop until the end of the file list under the movie directory.\n",
    "file_list = [f for f in os.listdir(movie_path) if os.path.isfile(os.path.join(movie_path, f)) and  f.endswith(\".mov\")]\n",
    "for filename in file_list:\n",
    "    source_file = os.path.join(movie_path, filename)\n",
    "    destination_dir = os.path.join(train_data_dir, os.path.splitext(filename)[0])\n",
    "    \n",
    "    # Make destination directory if not exist\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.mkdir(destination_dir)\n",
    "\n",
    "    # Open video file to capture the jpeg images\n",
    "    capture = cv2.VideoCapture(source_file)\n",
    "\n",
    "    img_count = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    # Loop until  EOF\n",
    "    while(capture.isOpened()):\n",
    "        \n",
    "        # Read one video frame\n",
    "        ret, frame = capture.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        # Pick up the frame if its position is the specified frame interval\n",
    "        if frame_count % frame_interval == 0:\n",
    "            img_file_name = os.path.join(destination_dir, str(img_count) + '.jpg')\n",
    "            cv2.imwrite(img_file_name, frame)\n",
    "            img_count += 1\n",
    "        frame_count += 1\n",
    "    # Close the current movie file\n",
    "    capture.release()\n",
    "    print('# of images & path:', img_count, 'images under' + destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 2: Configure output layers to meet your task\n",
    "\n",
    "I configure my own output layers to connect to the last layer of the base model. I have several options to configure this layers but I should remember the MobileNet is lightweight and fast model.\n",
    "\n",
    "1. Which do I use Flatten or GlobalAveragePooling2D as the input layer of my model?\n",
    "1. Which do I use relu or tanh as an activation as the fully connected layer?\n",
    "1. Do I use batch normarization?\n",
    "1. Do I use Dropout? What ratio do I set?\n",
    "\n",
    "Very large neural network like ResNet50 or VGG16 places the Flatten as the input layer of my own output layers but I do not think MobileNet should have the same function there since it has fully connected Dense layer next to the input layer. The parameter size that Flatten layer passes to the Dense layer will be 50176 (7ｘ7ｘ1024), and it makes the size of model around 115MB even though it is only 15MB if I place the GlobalAveragePooling2D function there.\n",
    "\n",
    "This configuration is just an example but my model shows good performance to resolve my task. You will need trial and error to understand whether BatchNormarization and Dropout works for your task as you expected or not. It will take longer time to try several conbination of configuration and parameters but you need to do that to get better model for your computer vision task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = MobileNet(include_top=False, weights='imagenet', input_tensor=input_tensor) \n",
    "\n",
    "# Make our own output layers\n",
    "x = base_model.output\n",
    "# Flatten layer is not suitable for MobileNet based model as it makes file size larger\n",
    "# x = Flatten(input_shape=base_model.output_shape[1:])(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu', name='fc1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_tensor = Dense(len(class_labels), activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Connect base model to our own output layers\n",
    "mymodel = Model(inputs=base_model.input, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 3: Train batch normarization layers in the base model\n",
    "\n",
    "MobileNet and ResNet50 has batch normarization layers and I need to update these layers even though I want to use transfer learning without updating any layers of the base model. The batch normarization layer passes the output data to the next layer with normarizing the batch input data to avoid overfitting.\n",
    "\n",
    "However, I have never seen that the traing loss getting converge if I set the trainable flag of the batch normarization layers to false since the layers no longer calcurate the average, standard deviation or variance. The layers use the original value to normarize the new training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 9, 9, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,493,573\n",
      "Trainable params: 286,085\n",
      "Non-trainable params: 3,207,488\n",
      "_________________________________________________________________\n",
      "Total Layers:  101\n",
      "Freezed Layers:69\n"
     ]
    }
   ],
   "source": [
    "# Set the trainable flag to true if the layer is batch normalization layer.\n",
    "freeze_layer_counts = 0\n",
    "for layer in mymodel.layers[:len(base_model.layers)]:\n",
    "\n",
    "    # MobileNet need to update its batch nomalization layer to converge the loss.\n",
    "    if layer.name.endswith('_bn'):\n",
    "        # You can understand the training loss never converge when you set this to false.\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        freeze_layer_counts = freeze_layer_counts + 1\n",
    "        layer.trainable = False\n",
    "\n",
    "# I need to update the paraemters for my additional layers.\n",
    "for layer in mymodel.layers[len(base_model.layers):]:\n",
    "    layer.trainable = True\n",
    "\n",
    "print('Model Structure:')\n",
    "mymodel.summary()\n",
    "print('Total Layers:  ' + str(len(mymodel.layers)))\n",
    "print('Freezed Layers:' + str(freeze_layer_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 4: Use Keras augmentation to avoid overfitting\n",
    "\n",
    "I have very limited volume of training dataset. It is less than 300 images for 5 classes. Basically it is quite small volume to learn, and the small dataset often causes the overfitting issue as you know. However, Keras has very strong data augmentation features. I can generate addtional images from my own training dataset. I can train the model with enough volume of the training dataset to avoid overfitting.\n",
    "\n",
    "Refer to [Image Preprocessing - ImageDataGenerator class](https://keras.io/preprocessing/image/) for more attribute of the ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 images belonging to 5 classes.\n",
      "Found 71 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=45,\n",
    "    zoom_range=0.3,\n",
    "    brightness_range=[0.1, 0.9],\n",
    "    channel_shift_range=50.0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=validation_data_split_rate)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    classes=class_labels,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = train_data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    classes=class_labels,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 5: Save the best performance model\n",
    "\n",
    "The last epoch does not always give me the best performance model. I often found the best performance model is generated on the way to the last epoch. I will miss the best model if I only save the model after the last epoch has ended. So, I save the model when it update its best \"loss\" at the end of each epoch. I save the model not only configuration but also its weight.\n",
    "\n",
    "In addtion, I tried early stopping but I commented out the code as it does not works for my model. My model sometimes get worth performance than previous epoch but a few epochs later it start improving the performance again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 128s 32s/step - loss: 2.6838 - acc: 0.2460 - val_loss: 2.2330 - val_acc: 0.1831\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.63226, saving model to ../result/mobilenet.h5\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 132s 33s/step - loss: 2.5476 - acc: 0.1653 - val_loss: 2.3284 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00002: loss improved from 2.63226 to 2.48569, saving model to ../result/mobilenet.h5\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 130s 32s/step - loss: 2.3541 - acc: 0.2702 - val_loss: 1.7162 - val_acc: 0.3521\n",
      "\n",
      "Epoch 00003: loss improved from 2.48569 to 2.36953, saving model to ../result/mobilenet.h5\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 124s 31s/step - loss: 1.9589 - acc: 0.3669 - val_loss: 1.4392 - val_acc: 0.4648\n",
      "\n",
      "Epoch 00004: loss improved from 2.36953 to 2.00425, saving model to ../result/mobilenet.h5\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 125s 31s/step - loss: 1.6808 - acc: 0.4355 - val_loss: 1.1178 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00005: loss improved from 2.00425 to 1.71914, saving model to ../result/mobilenet.h5\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 128s 32s/step - loss: 1.5138 - acc: 0.4798 - val_loss: 1.3574 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00006: loss improved from 1.71914 to 1.53824, saving model to ../result/mobilenet.h5\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 122s 30s/step - loss: 1.2313 - acc: 0.5443 - val_loss: 1.0452 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00007: loss improved from 1.53824 to 1.25788, saving model to ../result/mobilenet.h5\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 123s 31s/step - loss: 1.2315 - acc: 0.5727 - val_loss: 1.1087 - val_acc: 0.6479\n",
      "\n",
      "Epoch 00008: loss improved from 1.25788 to 1.14232, saving model to ../result/mobilenet.h5\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 123s 31s/step - loss: 0.9823 - acc: 0.6572 - val_loss: 0.7854 - val_acc: 0.6620\n",
      "\n",
      "Epoch 00009: loss improved from 1.14232 to 1.00751, saving model to ../result/mobilenet.h5\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 127s 32s/step - loss: 0.9750 - acc: 0.6451 - val_loss: 0.7856 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00010: loss did not improve from 1.00751\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 120s 30s/step - loss: 1.0183 - acc: 0.6250 - val_loss: 0.7211 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00011: loss improved from 1.00751 to 1.00332, saving model to ../result/mobilenet.h5\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 119s 30s/step - loss: 0.9308 - acc: 0.6209 - val_loss: 0.7575 - val_acc: 0.7606\n",
      "\n",
      "Epoch 00012: loss improved from 1.00332 to 0.97064, saving model to ../result/mobilenet.h5\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 118s 29s/step - loss: 0.8725 - acc: 0.6896 - val_loss: 0.8707 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00013: loss improved from 0.97064 to 0.83042, saving model to ../result/mobilenet.h5\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 125s 31s/step - loss: 0.8858 - acc: 0.6895 - val_loss: 0.8728 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.83042\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 108s 27s/step - loss: 0.7560 - acc: 0.7500 - val_loss: 0.7146 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00015: loss improved from 0.83042 to 0.73630, saving model to ../result/mobilenet.h5\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.7666 - acc: 0.7097 - val_loss: 0.7223 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.73630\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.6909 - acc: 0.7339 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00017: loss improved from 0.73630 to 0.68300, saving model to ../result/mobilenet.h5\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.6793 - acc: 0.7379 - val_loss: 0.4792 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00018: loss improved from 0.68300 to 0.68194, saving model to ../result/mobilenet.h5\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.5990 - acc: 0.7782 - val_loss: 0.5705 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00019: loss improved from 0.68194 to 0.59836, saving model to ../result/mobilenet.h5\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.6895 - acc: 0.7621 - val_loss: 0.3698 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.59836\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.6857 - acc: 0.7661 - val_loss: 0.4024 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.59836\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.4822 - acc: 0.8306 - val_loss: 0.5349 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00022: loss improved from 0.59836 to 0.48483, saving model to ../result/mobilenet.h5\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.5396 - acc: 0.8064 - val_loss: 0.3609 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.48483\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.5470 - acc: 0.8387 - val_loss: 0.3987 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.48483\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.5757 - acc: 0.7742 - val_loss: 0.4296 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.48483\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.5548 - acc: 0.8226 - val_loss: 0.2908 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.48483\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.5266 - acc: 0.7944 - val_loss: 0.4217 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.48483\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 122s 31s/step - loss: 0.4494 - acc: 0.8024 - val_loss: 0.4002 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00028: loss improved from 0.48483 to 0.45627, saving model to ../result/mobilenet.h5\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 126s 32s/step - loss: 0.3547 - acc: 0.8588 - val_loss: 0.3725 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00029: loss improved from 0.45627 to 0.37014, saving model to ../result/mobilenet.h5\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 120s 30s/step - loss: 0.4531 - acc: 0.8387 - val_loss: 0.3520 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.37014\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.4174 - acc: 0.8589 - val_loss: 0.4378 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.37014\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 119s 30s/step - loss: 0.4304 - acc: 0.8306 - val_loss: 0.4428 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.37014\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 128s 32s/step - loss: 0.4860 - acc: 0.8146 - val_loss: 0.3264 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.37014\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 128s 32s/step - loss: 0.4419 - acc: 0.8669 - val_loss: 0.2959 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.37014\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 120s 30s/step - loss: 0.3403 - acc: 0.8911 - val_loss: 0.2860 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00035: loss improved from 0.37014 to 0.35286, saving model to ../result/mobilenet.h5\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 124s 31s/step - loss: 0.3744 - acc: 0.8589 - val_loss: 0.4458 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.35286\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 119s 30s/step - loss: 0.3064 - acc: 0.9072 - val_loss: 0.3516 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00037: loss improved from 0.35286 to 0.31620, saving model to ../result/mobilenet.h5\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 108s 27s/step - loss: 0.4723 - acc: 0.8065 - val_loss: 0.4097 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.31620\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 108s 27s/step - loss: 0.4290 - acc: 0.8427 - val_loss: 0.3314 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.31620\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.3201 - acc: 0.8911 - val_loss: 0.3421 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00040: loss improved from 0.31620 to 0.30347, saving model to ../result/mobilenet.h5\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 110s 28s/step - loss: 0.3269 - acc: 0.8750 - val_loss: 0.2918 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00041: loss improved from 0.30347 to 0.30150, saving model to ../result/mobilenet.h5\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 110s 27s/step - loss: 0.3008 - acc: 0.9072 - val_loss: 0.3434 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.30150\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 116s 29s/step - loss: 0.3886 - acc: 0.8629 - val_loss: 0.3300 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.30150\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 113s 28s/step - loss: 0.3481 - acc: 0.8710 - val_loss: 0.4753 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.30150\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.3159 - acc: 0.9032 - val_loss: 0.2067 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.30150\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.3251 - acc: 0.8710 - val_loss: 0.3003 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.30150\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.3778 - acc: 0.8669 - val_loss: 0.2915 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.30150\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.3096 - acc: 0.8790 - val_loss: 0.2529 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.30150\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.3582 - acc: 0.8549 - val_loss: 0.2004 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.30150\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2935 - acc: 0.9073 - val_loss: 0.2214 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00050: loss improved from 0.30150 to 0.28932, saving model to ../result/mobilenet.h5\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2768 - acc: 0.8992 - val_loss: 0.2848 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00051: loss improved from 0.28932 to 0.27403, saving model to ../result/mobilenet.h5\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.3446 - acc: 0.8710 - val_loss: 0.3337 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.27403\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.2247 - acc: 0.9274 - val_loss: 0.2300 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00053: loss improved from 0.27403 to 0.21935, saving model to ../result/mobilenet.h5\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.3917 - acc: 0.8468 - val_loss: 0.1610 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.21935\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2418 - acc: 0.9193 - val_loss: 0.2674 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.21935\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.3202 - acc: 0.8790 - val_loss: 0.3132 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.21935\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 110s 28s/step - loss: 0.2754 - acc: 0.9113 - val_loss: 0.2020 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.21935\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.2544 - acc: 0.9153 - val_loss: 0.2209 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.21935\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.2541 - acc: 0.9234 - val_loss: 0.2519 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.21935\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.3093 - acc: 0.8871 - val_loss: 0.2809 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.21935\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 108s 27s/step - loss: 0.3180 - acc: 0.8911 - val_loss: 0.2569 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.21935\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.3177 - acc: 0.8508 - val_loss: 0.1930 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.21935\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.2787 - acc: 0.8911 - val_loss: 0.2048 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.21935\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 108s 27s/step - loss: 0.2299 - acc: 0.9153 - val_loss: 0.2238 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.21935\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2953 - acc: 0.8952 - val_loss: 0.2341 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.21935\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.2778 - acc: 0.9033 - val_loss: 0.1906 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.21935\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.3522 - acc: 0.8509 - val_loss: 0.2644 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.21935\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.2808 - acc: 0.8992 - val_loss: 0.2606 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.21935\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.2525 - acc: 0.8992 - val_loss: 0.2698 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.21935\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2078 - acc: 0.9435 - val_loss: 0.1952 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.21935\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2604 - acc: 0.9032 - val_loss: 0.2206 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.21935\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.2304 - acc: 0.9153 - val_loss: 0.1384 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00072: loss improved from 0.21935 to 0.20684, saving model to ../result/mobilenet.h5\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2509 - acc: 0.9194 - val_loss: 0.2035 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.20684\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.1742 - acc: 0.9435 - val_loss: 0.3043 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00074: loss improved from 0.20684 to 0.18465, saving model to ../result/mobilenet.h5\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2628 - acc: 0.9234 - val_loss: 0.1689 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.18465\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.2920 - acc: 0.8670 - val_loss: 0.1834 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.18465\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2027 - acc: 0.9315 - val_loss: 0.2010 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.18465\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.1954 - acc: 0.9314 - val_loss: 0.1374 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.18465\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2096 - acc: 0.9314 - val_loss: 0.1461 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.18465\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.3517 - acc: 0.8790 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.18465\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2496 - acc: 0.9274 - val_loss: 0.1392 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.18465\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.1923 - acc: 0.9476 - val_loss: 0.1726 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.18465\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2276 - acc: 0.9194 - val_loss: 0.2411 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.18465\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.2745 - acc: 0.8912 - val_loss: 0.1028 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.18465\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 106s 27s/step - loss: 0.1951 - acc: 0.9355 - val_loss: 0.1350 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.18465\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2279 - acc: 0.9113 - val_loss: 0.1330 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.18465\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2579 - acc: 0.8992 - val_loss: 0.1471 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.18465\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2178 - acc: 0.9274 - val_loss: 0.1285 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.18465\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2418 - acc: 0.9113 - val_loss: 0.1633 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.18465\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.1325 - acc: 0.9718 - val_loss: 0.1140 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00090: loss improved from 0.18465 to 0.13821, saving model to ../result/mobilenet.h5\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 110s 28s/step - loss: 0.1914 - acc: 0.9315 - val_loss: 0.1826 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.13821\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.2565 - acc: 0.8831 - val_loss: 0.2154 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.13821\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 109s 27s/step - loss: 0.2331 - acc: 0.9153 - val_loss: 0.1388 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.13821\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 107s 27s/step - loss: 0.2228 - acc: 0.8992 - val_loss: 0.2108 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.13821\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 106s 27s/step - loss: 0.1806 - acc: 0.9355 - val_loss: 0.2379 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.13821\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 105s 26s/step - loss: 0.1893 - acc: 0.9436 - val_loss: 0.1222 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.13821\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.1761 - acc: 0.9234 - val_loss: 0.1239 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.13821\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2311 - acc: 0.9033 - val_loss: 0.1665 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.13821\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.2184 - acc: 0.9113 - val_loss: 0.1968 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.13821\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 106s 26s/step - loss: 0.1170 - acc: 0.9758 - val_loss: 0.1373 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00100: loss improved from 0.13821 to 0.12067, saving model to ../result/mobilenet.h5\n",
      "Learning Time:  184.99 min.\n"
     ]
    }
   ],
   "source": [
    "print('Start training:')\n",
    "\n",
    "# Compile the model\n",
    "mymodel.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(\n",
    "    lr=1e-3, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "# Save the model if it has the best loss after an epoch training.\n",
    "checkpoint_cb = ModelCheckpoint(filepath=os.path.join(result_dir, 'mobilenet.h5'),\n",
    "                                monitor='loss',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=False,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "# Stop earlier when the training has stopped improving val_loss. \n",
    "# earystop_cb = EarlyStopping(monitor='val_loss',\n",
    "#                                 patience=0,\n",
    "#                                 verbose=1,\n",
    "#                                 mode='auto')\n",
    "\n",
    "# Transfer learning start\n",
    "start = time.time()\n",
    "history = mymodel.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(train_generator.samples / batch_size),\n",
    "    epochs=epoch_count,\n",
    "    callbacks=[checkpoint_cb],\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=math.ceil(validation_generator.samples / batch_size))\n",
    "\n",
    "# End learning\n",
    "process_time = (time.time() - start) / 60\n",
    "print('Learning Time: ', '{:.2f}'.format(process_time), 'min.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Point 6: Prepare model not only for Android but for iOS\n",
    "\n",
    "I can use the original format of model for Android but cannot use it for iOS. So, I convert the Keras model to CoreML model using coremltools. However, you will get \"ValueError: Unknown activation function:relu6\" message if you just try to convert to CoreML model.\n",
    "\n",
    "MobileNet has its own custom functions like relu6 that Keras does not know. So, you need to tell Keras those unknown functionns. I teach Keras what exactly relu6 and DepthwiseConv2D indicate by using CustomObjectScope. You can see the error when you commented out the first line of the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_3, <keras.engine.topology.InputLayer object at 0x13c801748>\n",
      "1 : conv1_pad, <keras.layers.convolutional.ZeroPadding2D object at 0x13c801668>\n",
      "2 : conv1, <keras.layers.convolutional.Conv2D object at 0x13c8019b0>\n",
      "3 : conv1_bn, <keras.layers.normalization.BatchNormalization object at 0x13c801898>\n",
      "4 : conv1_relu, <keras.layers.core.Activation object at 0x13c801a20>\n",
      "5 : conv_pad_1, <keras.layers.convolutional.ZeroPadding2D object at 0x13c801cf8>\n",
      "6 : conv_dw_1, <keras.layers.convolutional.DepthwiseConv2D object at 0x13c801d30>\n",
      "7 : conv_dw_1_bn, <keras.layers.normalization.BatchNormalization object at 0x13c801dd8>\n",
      "8 : conv_dw_1_relu, <keras.layers.core.Activation object at 0x13c801e48>\n",
      "9 : conv_pw_1, <keras.layers.convolutional.Conv2D object at 0x1377fb128>\n",
      "10 : conv_pw_1_bn, <keras.layers.normalization.BatchNormalization object at 0x1377fb278>\n",
      "11 : conv_pw_1_relu, <keras.layers.core.Activation object at 0x1377fb3c8>\n",
      "12 : conv_pad_2, <keras.layers.convolutional.ZeroPadding2D object at 0x1377fb400>\n",
      "13 : conv_dw_2, <keras.layers.convolutional.DepthwiseConv2D object at 0x1377fb470>\n",
      "14 : conv_dw_2_bn, <keras.layers.normalization.BatchNormalization object at 0x1377fb4e0>\n",
      "15 : conv_dw_2_relu, <keras.layers.core.Activation object at 0x1377fb7b8>\n",
      "16 : conv_pw_2, <keras.layers.convolutional.Conv2D object at 0x1377fb7f0>\n",
      "17 : conv_pw_2_bn, <keras.layers.normalization.BatchNormalization object at 0x1377fb940>\n",
      "18 : conv_pw_2_relu, <keras.layers.core.Activation object at 0x1377fba90>\n",
      "19 : conv_pad_3, <keras.layers.convolutional.ZeroPadding2D object at 0x1377fbac8>\n",
      "20 : conv_dw_3, <keras.layers.convolutional.DepthwiseConv2D object at 0x1377fbb38>\n",
      "21 : conv_dw_3_bn, <keras.layers.normalization.BatchNormalization object at 0x1377fbba8>\n",
      "22 : conv_dw_3_relu, <keras.layers.core.Activation object at 0x1377fbe80>\n",
      "23 : conv_pw_3, <keras.layers.convolutional.Conv2D object at 0x1377fbeb8>\n",
      "24 : conv_pw_3_bn, <keras.layers.normalization.BatchNormalization object at 0x13c801fd0>\n",
      "25 : conv_pw_3_relu, <keras.layers.core.Activation object at 0x1377ff198>\n",
      "26 : conv_pad_4, <keras.layers.convolutional.ZeroPadding2D object at 0x1377ff1d0>\n",
      "27 : conv_dw_4, <keras.layers.convolutional.DepthwiseConv2D object at 0x1377ff240>\n",
      "28 : conv_dw_4_bn, <keras.layers.normalization.BatchNormalization object at 0x1377ff2b0>\n",
      "29 : conv_dw_4_relu, <keras.layers.core.Activation object at 0x1377ff588>\n",
      "30 : conv_pw_4, <keras.layers.convolutional.Conv2D object at 0x1377ff5c0>\n",
      "31 : conv_pw_4_bn, <keras.layers.normalization.BatchNormalization object at 0x1377ff710>\n",
      "32 : conv_pw_4_relu, <keras.layers.core.Activation object at 0x1377ff860>\n",
      "33 : conv_pad_5, <keras.layers.convolutional.ZeroPadding2D object at 0x1377ff898>\n",
      "34 : conv_dw_5, <keras.layers.convolutional.DepthwiseConv2D object at 0x1377ff908>\n",
      "35 : conv_dw_5_bn, <keras.layers.normalization.BatchNormalization object at 0x1377ff978>\n",
      "36 : conv_dw_5_relu, <keras.layers.core.Activation object at 0x1377ffc50>\n",
      "37 : conv_pw_5, <keras.layers.convolutional.Conv2D object at 0x1377ffc88>\n",
      "38 : conv_pw_5_bn, <keras.layers.normalization.BatchNormalization object at 0x1377ffdd8>\n",
      "39 : conv_pw_5_relu, <keras.layers.core.Activation object at 0x1377fff28>\n",
      "40 : conv_pad_6, <keras.layers.convolutional.ZeroPadding2D object at 0x1377fff60>\n",
      "41 : conv_dw_6, <keras.layers.convolutional.DepthwiseConv2D object at 0x1377fbf60>\n",
      "42 : conv_dw_6_bn, <keras.layers.normalization.BatchNormalization object at 0x137808080>\n",
      "43 : conv_dw_6_relu, <keras.layers.core.Activation object at 0x137808358>\n",
      "44 : conv_pw_6, <keras.layers.convolutional.Conv2D object at 0x137808390>\n",
      "45 : conv_pw_6_bn, <keras.layers.normalization.BatchNormalization object at 0x1378084e0>\n",
      "46 : conv_pw_6_relu, <keras.layers.core.Activation object at 0x137808630>\n",
      "47 : conv_pad_7, <keras.layers.convolutional.ZeroPadding2D object at 0x137808668>\n",
      "48 : conv_dw_7, <keras.layers.convolutional.DepthwiseConv2D object at 0x1378086d8>\n",
      "49 : conv_dw_7_bn, <keras.layers.normalization.BatchNormalization object at 0x137808748>\n",
      "50 : conv_dw_7_relu, <keras.layers.core.Activation object at 0x137808a20>\n",
      "51 : conv_pw_7, <keras.layers.convolutional.Conv2D object at 0x137808a58>\n",
      "52 : conv_pw_7_bn, <keras.layers.normalization.BatchNormalization object at 0x137808ba8>\n",
      "53 : conv_pw_7_relu, <keras.layers.core.Activation object at 0x137808cf8>\n",
      "54 : conv_pad_8, <keras.layers.convolutional.ZeroPadding2D object at 0x137808d30>\n",
      "55 : conv_dw_8, <keras.layers.convolutional.DepthwiseConv2D object at 0x137808da0>\n",
      "56 : conv_dw_8_bn, <keras.layers.normalization.BatchNormalization object at 0x137808e10>\n",
      "57 : conv_dw_8_relu, <keras.layers.core.Activation object at 0x1377fffd0>\n",
      "58 : conv_pw_8, <keras.layers.convolutional.Conv2D object at 0x137819160>\n",
      "59 : conv_pw_8_bn, <keras.layers.normalization.BatchNormalization object at 0x1378192b0>\n",
      "60 : conv_pw_8_relu, <keras.layers.core.Activation object at 0x137819400>\n",
      "61 : conv_pad_9, <keras.layers.convolutional.ZeroPadding2D object at 0x137819438>\n",
      "62 : conv_dw_9, <keras.layers.convolutional.DepthwiseConv2D object at 0x1378194a8>\n",
      "63 : conv_dw_9_bn, <keras.layers.normalization.BatchNormalization object at 0x137819518>\n",
      "64 : conv_dw_9_relu, <keras.layers.core.Activation object at 0x1378197f0>\n",
      "65 : conv_pw_9, <keras.layers.convolutional.Conv2D object at 0x137819828>\n",
      "66 : conv_pw_9_bn, <keras.layers.normalization.BatchNormalization object at 0x137819978>\n",
      "67 : conv_pw_9_relu, <keras.layers.core.Activation object at 0x137819ac8>\n",
      "68 : conv_pad_10, <keras.layers.convolutional.ZeroPadding2D object at 0x137819b00>\n",
      "69 : conv_dw_10, <keras.layers.convolutional.DepthwiseConv2D object at 0x137819b70>\n",
      "70 : conv_dw_10_bn, <keras.layers.normalization.BatchNormalization object at 0x137819be0>\n",
      "71 : conv_dw_10_relu, <keras.layers.core.Activation object at 0x137819eb8>\n",
      "72 : conv_pw_10, <keras.layers.convolutional.Conv2D object at 0x137819ef0>\n",
      "73 : conv_pw_10_bn, <keras.layers.normalization.BatchNormalization object at 0x137808f60>\n",
      "74 : conv_pw_10_relu, <keras.layers.core.Activation object at 0x137820208>\n",
      "75 : conv_pad_11, <keras.layers.convolutional.ZeroPadding2D object at 0x137820240>\n",
      "76 : conv_dw_11, <keras.layers.convolutional.DepthwiseConv2D object at 0x137820198>\n",
      "77 : conv_dw_11_bn, <keras.layers.normalization.BatchNormalization object at 0x137820320>\n",
      "78 : conv_dw_11_relu, <keras.layers.core.Activation object at 0x1378205f8>\n",
      "79 : conv_pw_11, <keras.layers.convolutional.Conv2D object at 0x1378206a0>\n",
      "80 : conv_pw_11_bn, <keras.layers.normalization.BatchNormalization object at 0x137820630>\n",
      "81 : conv_pw_11_relu, <keras.layers.core.Activation object at 0x1378208d0>\n",
      "82 : conv_pad_12, <keras.layers.convolutional.ZeroPadding2D object at 0x137820908>\n",
      "83 : conv_dw_12, <keras.layers.convolutional.DepthwiseConv2D object at 0x1378209b0>\n",
      "84 : conv_dw_12_bn, <keras.layers.normalization.BatchNormalization object at 0x137820a20>\n",
      "85 : conv_dw_12_relu, <keras.layers.core.Activation object at 0x137820cc0>\n",
      "86 : conv_pw_12, <keras.layers.convolutional.Conv2D object at 0x137820ba8>\n",
      "87 : conv_pw_12_bn, <keras.layers.normalization.BatchNormalization object at 0x137820e48>\n",
      "88 : conv_pw_12_relu, <keras.layers.core.Activation object at 0x137820f60>\n",
      "89 : conv_pad_13, <keras.layers.convolutional.ZeroPadding2D object at 0x137820d68>\n",
      "90 : conv_dw_13, <keras.layers.convolutional.DepthwiseConv2D object at 0x137826048>\n",
      "91 : conv_dw_13_bn, <keras.layers.normalization.BatchNormalization object at 0x1378260b8>\n",
      "92 : conv_dw_13_relu, <keras.layers.core.Activation object at 0x137826390>\n",
      "93 : conv_pw_13, <keras.layers.convolutional.Conv2D object at 0x1378263c8>\n",
      "94 : conv_pw_13_bn, <keras.layers.normalization.BatchNormalization object at 0x137826518>\n",
      "95 : conv_pw_13_relu, <keras.layers.core.Activation object at 0x137826668>\n",
      "96 : global_average_pooling2d_3, <keras.layers.pooling.GlobalAveragePooling2D object at 0x1378266a0>\n",
      "97 : fc1, <keras.layers.core.Dense object at 0x137826710>\n",
      "98 : fc1__activation__, <keras.layers.core.Activation object at 0x144d33710>\n",
      "99 : batch_normalization_3, <keras.layers.normalization.BatchNormalization object at 0x137826860>\n",
      "100 : predictions, <keras.layers.core.Dense object at 0x1378269b0>\n",
      "101 : predictions__activation__, <keras.layers.core.Activation object at 0x144d3e3c8>\n"
     ]
    }
   ],
   "source": [
    "# You will get \"ValueError: Unknown activation function:relu6\" if you commented out the following first line of code.\n",
    "with CustomObjectScope({'relu6': mobilenet.relu6, 'DepthwiseConv2D': mobilenet.DepthwiseConv2D}):\n",
    "    my_coreml_model = coremltools.converters.keras.convert(os.path.join(result_dir, 'mobilenet.h5'),\n",
    "        is_bgr=False,\n",
    "        image_scale=1.0/255,\n",
    "        input_names='image',\n",
    "        image_input_names='image',\n",
    "        class_labels=class_labels)\n",
    "    my_coreml_model.save(os.path.join(result_dir, 'mobilenet.mlmodel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write History\n",
    "\n",
    "I write the history data into the file to record the progress of the training. I can see how the training goes after completing the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = os.path.join(result_dir, 'training_result.txt')\n",
    "loss = history.history['loss']\n",
    "acc = history.history['acc']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_acc']\n",
    "nb_epoch = len(acc)\n",
    "\n",
    "with open(result_file, \"w\") as fp:\n",
    "    fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
    "    for i in range(nb_epoch):\n",
    "        fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" %\n",
    "                    (i, loss[i], acc[i], val_loss[i], val_acc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the learning curve\n",
    "\n",
    "I plot the learning curve and then draw the graph to help better understanding of the training progress. I turned training loss value to negative to converge both validation / training loss toward zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = []\n",
    "train_error_list = []\n",
    "train_acc_list = []\n",
    "val_error_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "with open(result_file) as fp:\n",
    "    fp.readline()  # skip title\n",
    "    for line in fp:\n",
    "        line = line.rstrip()\n",
    "        cols = line.split('\\t')\n",
    "\n",
    "        epoch = int(cols[0])\n",
    "        train_error = float(cols[1]) * -1\n",
    "        train_acc = float(cols[2])\n",
    "        val_error = float(cols[3])\n",
    "        val_acc = float(cols[4])\n",
    "\n",
    "        epoch_list.append(epoch)\n",
    "        train_error_list.append(train_error)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_error_list.append(val_error)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch_list, train_error_list, 'b-', marker='.', label='training')\n",
    "plt.plot(epoch_list, val_error_list, 'r-', marker='.', label='validation')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.savefig(result_file + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
